{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e5f429f-cfe8-42c5-8bc1-d88a21d6857a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\acer\\1_Project\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e5f608d-788a-4266-92f8-8c5f9d43b6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Display Video Frames and FPS\n",
    "# ==============================\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Step 1: Open webcam (0 = default camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Step 2: Check if webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam\")\n",
    "    exit()\n",
    "\n",
    "# Step 3: Variables for FPS calculation\n",
    "prev_time = 0\n",
    "\n",
    "while True:\n",
    "    # Step 4: Read one frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # If frame not captured correctly, break the loop\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    # Step 5: Calculate Frames Per Second (FPS)\n",
    "    current_time = time.time()\n",
    "    fps = 1 / (current_time - prev_time) if prev_time else 0\n",
    "    prev_time = current_time\n",
    "\n",
    "    # Step 6: Display FPS on the video frame\n",
    "    cv2.putText(frame, f'FPS: {int(fps)}', (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Step 7: Display the video frame in a window\n",
    "    cv2.imshow(\"Video Frame\", frame)\n",
    "\n",
    "    # Step 8: Exit when 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Step 9: Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7022c859-9b80-46a6-bbc3-275dff0ee998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to quit capturing video...\n",
      "Saved: saved_frames\\frame_20251106_194702_10.jpg\n",
      "Saved: saved_frames\\frame_20251106_194703_20.jpg\n",
      "Saved: saved_frames\\frame_20251106_194703_30.jpg\n",
      "Saved: saved_frames\\frame_20251106_194703_40.jpg\n",
      "Saved: saved_frames\\frame_20251106_194704_50.jpg\n",
      "Saved: saved_frames\\frame_20251106_194704_60.jpg\n",
      "Saved: saved_frames\\frame_20251106_194704_70.jpg\n",
      "Saved: saved_frames\\frame_20251106_194705_80.jpg\n",
      "Saved: saved_frames\\frame_20251106_194705_90.jpg\n",
      "Saved: saved_frames\\frame_20251106_194705_100.jpg\n",
      "Saved: saved_frames\\frame_20251106_194706_110.jpg\n",
      "Saved: saved_frames\\frame_20251106_194706_120.jpg\n",
      "\n",
      "Video capture ended.\n",
      "Images saved in folder: 'C:\\Users\\acer\\1_Project\\saved_frames'\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Capture Video Frames and Save as Images\n",
    "# ==========================================\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Step 1: Create a folder to save captured images\n",
    "save_folder = \"saved_frames\"\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# Step 2: Open the webcam (0 = default camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Step 3: Check if the webcam opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam\")\n",
    "    exit()\n",
    "\n",
    "# Step 4: Variables for FPS calculation and frame count\n",
    "prev_time = 0\n",
    "frame_count = 0\n",
    "\n",
    "# Step 5: How often to save frames (e.g., every 10th frame)\n",
    "save_interval = 10  # Change this to 1 to save every frame\n",
    "\n",
    "print(\"Press 'q' to quit capturing video...\")\n",
    "\n",
    "while True:\n",
    "    # Step 6: Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    # Step 7: Calculate FPS\n",
    "    current_time = time.time()\n",
    "    fps = 1 / (current_time - prev_time) if prev_time else 0\n",
    "    prev_time = current_time\n",
    "\n",
    "    # Step 8: Display FPS on the frame\n",
    "    cv2.putText(frame, f'FPS: {int(fps)}', (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Step 9: Display the frame in a window\n",
    "    cv2.imshow(\"Video Frame\", frame)\n",
    "\n",
    "    # Step 10: Save every Nth frame as an image file\n",
    "    frame_count += 1\n",
    "    if frame_count % save_interval == 0:\n",
    "        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = os.path.join(save_folder, f\"frame_{timestamp}_{frame_count}.jpg\")\n",
    "        cv2.imwrite(filename, frame)\n",
    "        print(f\"Saved: {filename}\")\n",
    "\n",
    "    # Step 11: Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Step 12: Release camera and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"\\nVideo capture ended.\")\n",
    "print(f\"Images saved in folder: '{os.path.abspath(save_folder)}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d54ae5e9-c95a-469c-95ff-cda100401754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Create a blank image (black background)\n",
    "img = np.zeros((500, 700, 3), dtype=np.uint8)\n",
    "\n",
    "# Step 2: Draw a rectangle\n",
    "# cv2.rectangle(image, top_left_corner, bottom_right_corner, color, thickness)\n",
    "cv2.rectangle(img, (50, 50), (250, 200), (0, 255, 0), 3)\n",
    "\n",
    "# Step 3: Draw a filled rectangle\n",
    "cv2.rectangle(img, (300, 50), (500, 200), (255, 0, 0), -1)  # -1 = filled\n",
    "\n",
    "# Step 4: Draw a circle\n",
    "# cv2.circle(image, center, radius, color, thickness)\n",
    "cv2.circle(img, (150, 350), 60, (0, 0, 255), 5)\n",
    "\n",
    "# Step 5: Draw a filled circle\n",
    "cv2.circle(img, (400, 350), 60, (0, 255, 255), -1)\n",
    "\n",
    "# Step 6: Draw a line\n",
    "# cv2.line(image, start_point, end_point, color, thickness)\n",
    "cv2.line(img, (50, 400), (600, 400), (255, 255, 255), 2)\n",
    "\n",
    "# Step 7: Add text\n",
    "# cv2.putText(image, text, position, font, scale, color, thickness)\n",
    "cv2.putText(img, \"OpenCV Drawing Demo\", (100, 470),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "# Step 8: Display the image\n",
    "cv2.imshow(\"Drawing on Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e9e5aa4-58ce-484d-a58e-0c7dfce98ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Draw rectangle and text on video frame\n",
    "    cv2.rectangle(frame, (100, 100), (300, 300), (0, 255, 0), 2)\n",
    "    cv2.putText(frame, \"Live Annotation\", (110, 90),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Live Video Annotation\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6364ee-587a-44c4-82d9-e6ab36dfb78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "hand_landmarks_webcam.py\n",
    "\n",
    "Real-time hand landmark detection using MediaPipe and OpenCV.\n",
    "\n",
    "Dependencies:\n",
    "    pip install opencv-python mediapipe\n",
    "\n",
    "Usage:\n",
    "    python hand_landmarks_webcam.py\n",
    "\n",
    "Features:\n",
    "- Opens the default webcam (index 0).\n",
    "- Runs MediaPipe Hands to detect up to 2 hands.\n",
    "- Draws 21 landmarks and connections on each detected hand.\n",
    "- Shows handedness (Left/Right) and confidence.\n",
    "- Displays FPS (frames per second).\n",
    "- Press 'q' to quit.\n",
    "\n",
    "Notes:\n",
    "- Run this as a standalone script (not inside restricted notebook environments).\n",
    "- If camera index 0 doesn't work, try 1, 2, etc.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp\n",
    "\n",
    "def main(camera_index=0, max_num_hands=2, detection_confidence=0.6, tracking_confidence=0.6):\n",
    "    # Initialize MediaPipe Hands and drawing utilities\n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=max_num_hands,\n",
    "        min_detection_confidence=detection_confidence,\n",
    "        min_tracking_confidence=tracking_confidence\n",
    "    )\n",
    "\n",
    "    # Open webcam\n",
    "    cap = cv2.VideoCapture(camera_index)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open webcam (index={camera_index})\")\n",
    "        return\n",
    "\n",
    "    prev_time = 0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame\")\n",
    "                break\n",
    "\n",
    "            # Flip the frame horizontally for a selfie-view display (optional)\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "            # Convert BGR (OpenCV) to RGB (MediaPipe)\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Process with MediaPipe Hands\n",
    "            results = hands.process(frame_rgb)\n",
    "\n",
    "            # If hands are detected, draw landmarks\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks, handedness in zip(results.multi_hand_landmarks,\n",
    "                                                      results.multi_handedness):\n",
    "                    # Draw hand landmarks and connections with default styling\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        frame,\n",
    "                        hand_landmarks,\n",
    "                        mp_hands.HAND_CONNECTIONS,\n",
    "                        mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                        mp_drawing_styles.get_default_hand_connections_style()\n",
    "                    )\n",
    "\n",
    "                    # Extract handedness label and score\n",
    "                    label = handedness.classification[0].label\n",
    "                    score = handedness.classification[0].score\n",
    "                    # Compute a position to put the label: use the wrist landmark (landmark 0)\n",
    "                    h, w, _ = frame.shape\n",
    "                    wrist = hand_landmarks.landmark[0]\n",
    "                    cx, cy = int(wrist.x * w), int(wrist.y * h)\n",
    "                    text = f\"{label}: {score:.2f}\"\n",
    "                    cv2.putText(frame, text, (cx - 20, cy - 20),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                    # (Optional) print landmark coordinates to console. Comment this out if noisy.\n",
    "                    # for idx, lm in enumerate(hand_landmarks.landmark):\n",
    "                    #     print(f\"Landmark {idx}: (x={lm.x:.3f}, y={lm.y:.3f}, z={lm.z:.3f})\")\n",
    "\n",
    "            # FPS calculation\n",
    "            curr_time = time.time()\n",
    "            fps = 1 / (curr_time - prev_time) if (curr_time - prev_time) > 0 else 0\n",
    "            prev_time = curr_time\n",
    "            cv2.putText(frame, f\"FPS: {int(fps)}\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "            # Show the frame\n",
    "            cv2.imshow(\"MediaPipe Hands - Press 'q' to Quit\", frame)\n",
    "\n",
    "            # Exit loop on 'q' key press\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        hands.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cv_project)",
   "language": "python",
   "name": "cv_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
