{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e387fab8-3965-46ae-b18c-be5b376bba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad065ab1-93c8-42b3-8d91-624d4dd949d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# --- 1. Distance Calculation Function (Euclidean Distance) ---\n",
    "def calculate_distance(p1, p2):\n",
    "    \"\"\"Calculates the 2D Euclidean distance between two points (x, y).\"\"\"\n",
    "    x1, y1 = p1\n",
    "    x2, y2 = p2\n",
    "    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "# --- 2. Initialize MediaPipe and OpenCV ---\n",
    "mp_hands = mp.solutions.hands\n",
    "# Set up the Hand detection object\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "mp_draw = mp.solutions.drawing_utils # Utility for drawing landmarks\n",
    "\n",
    "cap = cv2.VideoCapture(0) # Open the default webcam (index 0)\n",
    "\n",
    "# --- 3. Main Loop for Frame Processing ---\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "\n",
    "    # Flip the frame horizontally for a natural, mirror-like view\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Get frame dimensions\n",
    "    h, w, c = frame.shape\n",
    "\n",
    "    # Convert the BGR image to RGB for MediaPipe\n",
    "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the frame to find hand landmarks\n",
    "    results = hands.process(img_rgb)\n",
    "    \n",
    "    # --- 4. Process Landmarks and Calculate Distance ---\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            \n",
    "            # Draw the full set of 21 landmarks and connections\n",
    "            mp_draw.draw_landmarks(\n",
    "                frame, \n",
    "                hand_landmarks, \n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_draw.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2), # Landmark color\n",
    "                mp_draw.DrawingSpec(color=(255, 255, 255), thickness=2, circle_radius=2) # Connection color\n",
    "            )\n",
    "\n",
    "            # Get coordinates for Thumb Tip (Landmark ID 4) and Little Finger Tip (Landmark ID 20)\n",
    "            \n",
    "            # THUMB TIP (ID 4)\n",
    "            lm_4 = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "            x4, y4 = int(lm_4.x * w), int(lm_4.y * h)\n",
    "            \n",
    "            # LITTLE FINGER TIP (ID 20)\n",
    "            lm_20 = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP]\n",
    "            x20, y20 = int(lm_20.x * w), int(lm_20.y * h)\n",
    "            \n",
    "            # Highlight the specific points\n",
    "            cv2.circle(frame, (x4, y4), 10, (255, 0, 0), cv2.FILLED)  # Blue circle for thumb\n",
    "            cv2.circle(frame, (x20, y20), 10, (0, 0, 255), cv2.FILLED) # Red circle for pinky\n",
    "            \n",
    "            # Draw a line connecting the points\n",
    "            cv2.line(frame, (x4, y4), (x20, y20), (0, 255, 255), 3) # Yellow line\n",
    "            \n",
    "            # Calculate the distance\n",
    "            distance = calculate_distance((x4, y4), (x20, y20))\n",
    "            \n",
    "            # Display the distance on the frame\n",
    "            cv2.putText(\n",
    "                frame, \n",
    "                f'Distance: {int(distance)} px', \n",
    "                (20, 40), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                1, \n",
    "                (255, 255, 255), \n",
    "                2, \n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "    # --- 5. Display the output frame ---\n",
    "    cv2.imshow('Hand Gesture Volume Control', frame)\n",
    "    \n",
    "    # Exit loop on 'q' press\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# --- 6. Cleanup ---\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59f7be4f-502d-4e31-b5d3-6c889aeb35f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: image \"pyimage67\" doesn't exist\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "from google.protobuf.json_format import MessageToDict \n",
    "\n",
    "# --- MediaPipe Setup (No change) ---\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    "    max_num_hands=2\n",
    ")\n",
    "\n",
    "# Landmark indices for Tips (No change)\n",
    "THUMB_TIP_IDX = 4\n",
    "FINGER_TIPS_INDICES = {\n",
    "    \"Index Finger\": 8,\n",
    "    \"Middle Finger\": 12,\n",
    "    \"Ring Finger\": 16,\n",
    "    \"Pinky Finger\": 20,\n",
    "}\n",
    "\n",
    "# --- Distance Calculation Function (No change) ---\n",
    "def calculate_distance(df, lm_a_idx, lm_b_idx):\n",
    "    \"\"\"Calculates the 3D normalized distance between two landmarks.\"\"\"\n",
    "    lm_a = df.loc[lm_a_idx]\n",
    "    lm_b = df.loc[lm_b_idx]\n",
    "    norm_dist = np.sqrt(\n",
    "        (lm_a[\"x_norm\"] - lm_b[\"x_norm\"])**2 +\n",
    "        (lm_a[\"y_norm\"] - lm_b[\"y_norm\"])**2 +\n",
    "        (lm_a[\"z_norm\"] - lm_b[\"z_norm\"])**2\n",
    "    )\n",
    "    return norm_dist\n",
    "\n",
    "# --- Tkinter Application Class (Updated update_video) ---\n",
    "class HandTrackingApp:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"✋ Hand Gesture Analyzer (Live Feed Fixed)\")\n",
    "        master.geometry(\"1000x700\")\n",
    "        master.configure(bg=\"#f4f7f6\")\n",
    "\n",
    "        # --- Frames for layout ---\n",
    "        self.main_frame = ttk.Frame(master, padding=\"15 15 15 15\")\n",
    "        self.main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.video_frame = ttk.LabelFrame(self.main_frame, text=\"Live Hand Tracking\", padding=\"10 10 10 10\")\n",
    "        self.video_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "\n",
    "        self.data_frame = ttk.Frame(self.main_frame, padding=\"10 10 10 10\", width=300)\n",
    "        self.data_frame.pack(side=tk.RIGHT, fill=tk.Y, padx=10, pady=10)\n",
    "        \n",
    "        # Handedness Header\n",
    "        self.handedness_label = ttk.Label(self.data_frame, text=\"Detecting Hand...\", font=('Arial', 16, 'bold'), foreground='navy')\n",
    "        self.handedness_label.pack(anchor='w', pady=(0, 15))\n",
    "\n",
    "        # --- Video Canvas (Display) ---\n",
    "        self.video_label = tk.Label(self.video_frame, bg=\"black\")\n",
    "        self.video_label.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # --- Data Labels ---\n",
    "        self.distance_labels = {}\n",
    "        for finger_name in FINGER_TIPS_INDICES.keys():\n",
    "            label_text = f\"↔️ {finger_name} Distance:\"\n",
    "            label = ttk.Label(self.data_frame, text=label_text, font=('Arial', 12, 'bold'))\n",
    "            label.pack(anchor='w', pady=(10, 2))\n",
    "            \n",
    "            value_label = ttk.Label(self.data_frame, text=\"--.-- (Normalized)\", font=('Courier', 14))\n",
    "            value_label.pack(anchor='w', pady=(0, 10))\n",
    "            self.distance_labels[finger_name] = value_label\n",
    "\n",
    "        # --- Status Label ---\n",
    "        self.status_label = ttk.Label(self.data_frame, text=\"Status: Initializing...\", font=('Arial', 10), foreground='gray')\n",
    "        self.status_label.pack(anchor='s', pady=(20, 0))\n",
    "\n",
    "        # --- Webcam Setup ---\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        if not self.cap.isOpened():\n",
    "            self.status_label.config(text=\"Status: CAMERA ERROR! Check connection or permissions.\", foreground='red')\n",
    "            return\n",
    "        \n",
    "        self.hands_processor = hands \n",
    "        self.update_video()\n",
    "\n",
    "    def update_video(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            img_h, img_w = frame.shape[:2]\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            results = self.hands_processor.process(frame_rgb)\n",
    "            \n",
    "            annotated_frame = frame.copy()\n",
    "            status_text = \"No Hand Detected\"\n",
    "            status_color = 'orange'\n",
    "            \n",
    "            self.handedness_label.config(text=\"No Hand Detected\", foreground='navy')\n",
    "\n",
    "            if results.multi_hand_landmarks and len(results.multi_hand_landmarks) > 0:\n",
    "                hand_landmarks = results.multi_hand_landmarks[0]\n",
    "                \n",
    "                handedness_proto = results.multi_handedness[0]\n",
    "                handedness_dict = MessageToDict(handedness_proto)\n",
    "                handedness = handedness_dict['classification'][0]['label'] \n",
    "                \n",
    "                self.handedness_label.config(text=f\"Hand Detected: {handedness}\", \n",
    "                                             foreground='darkgreen' if handedness == 'Right' else 'darkred')\n",
    "                \n",
    "                mp_drawing.draw_landmarks(\n",
    "                    annotated_frame, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(0, 255, 100), thickness=2, circle_radius=4), \n",
    "                    mp_drawing.DrawingSpec(color=(200, 200, 255), thickness=2, circle_radius=2)\n",
    "                )\n",
    "\n",
    "                rows = []\n",
    "                for idx, lm in enumerate(hand_landmarks.landmark):\n",
    "                    rows.append({\n",
    "                        \"index\": idx,\n",
    "                        \"x_norm\": lm.x, \"y_norm\": lm.y, \"z_norm\": lm.z,\n",
    "                        \"x_px\": int(lm.x * img_w), \"y_px\": int(lm.y * img_h)\n",
    "                    })\n",
    "                df = pd.DataFrame(rows).set_index(\"index\")\n",
    "\n",
    "                status_text = f\"Tracking {handedness} Hand\"\n",
    "                status_color = 'green'\n",
    "                \n",
    "                for finger_name, tip_idx in FINGER_TIPS_INDICES.items():\n",
    "                    if tip_idx in df.index and THUMB_TIP_IDX in df.index:\n",
    "                        norm_dist = calculate_distance(df, THUMB_TIP_IDX, tip_idx)\n",
    "                        self.distance_labels[finger_name].config(text=f\"{norm_dist:.4f} (Normalized)\", foreground='green')\n",
    "                        \n",
    "                        thumb_tip = df.loc[THUMB_TIP_IDX]\n",
    "                        finger_tip = df.loc[tip_idx]\n",
    "                        cv2.line(annotated_frame, \n",
    "                                 (thumb_tip[\"x_px\"], thumb_tip[\"y_px\"]),\n",
    "                                 (finger_tip[\"x_px\"], finger_tip[\"y_px\"]),\n",
    "                                 (0, 255, 0), 2)\n",
    "                    else:\n",
    "                        self.distance_labels[finger_name].config(text=\"--.-- (Missing Landmark)\", foreground='red')\n",
    "            \n",
    "            else:\n",
    "                for label in self.distance_labels.values():\n",
    "                    label.config(text=\"--.-- (Normalized)\", foreground='gray')\n",
    "\n",
    "\n",
    "            self.status_label.config(text=f\"Status: {status_text}\", foreground=status_color)\n",
    "\n",
    "            # Convert to PIL Image for Tkinter\n",
    "            img = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(img)\n",
    "            \n",
    "            width, height = self.video_label.winfo_width(), self.video_label.winfo_height()\n",
    "            if width > 10 and height > 10: \n",
    "                img = img.resize((width, height), Image.Resampling.LANCZOS)\n",
    "            \n",
    "            # --- THE FIX APPLIED HERE ---\n",
    "            self.photo = ImageTk.PhotoImage(image=img)\n",
    "            self.video_label.config(image=self.photo)\n",
    "            self.video_label.image = self.photo # IMPORTANT: Keep the reference!\n",
    "\n",
    "        # Loop the update function\n",
    "        self.master.after(10, self.update_video) \n",
    "\n",
    "    def on_closing(self):\n",
    "        print(\"Closing application and releasing webcam...\")\n",
    "        self.cap.release()\n",
    "        self.hands_processor.close()\n",
    "        self.master.destroy()\n",
    "\n",
    "# --- Main Execution (No change) ---\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        root = tk.Tk()\n",
    "        style = ttk.Style(root)\n",
    "        style.theme_use('clam') \n",
    "        \n",
    "        app = HandTrackingApp(root)\n",
    "        root.protocol(\"WM_DELETE_WINDOW\", app.on_closing)\n",
    "        root.mainloop()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        hands.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b14caf0b-802c-4954-8f68-a6d3cbc01bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python310\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\acer\\.conda\\envs\\cv_project\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\acer\\.conda\\envs\\cv_project\\lib\\tkinter\\__init__.py\", line 839, in callit\n",
      "    func(*args)\n",
      "  File \"C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_20104\\2394491618.py\", line 150, in update_video\n",
      "    cv2.line(annotated_frame,\n",
      "cv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'line'\n",
      "> Overload resolution failed:\n",
      ">  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n",
      ">  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing application and releasing webcam...\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "# This import is required to correctly parse MediaPipe's handedness data\n",
    "from google.protobuf.json_format import MessageToDict \n",
    "\n",
    "# --- MediaPipe Setup ---\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    "    max_num_hands=2\n",
    ")\n",
    "\n",
    "# Landmark indices for Tips\n",
    "THUMB_TIP_IDX = 4\n",
    "FINGER_TIPS_INDICES = {\n",
    "    \"Index Finger\": 8,\n",
    "    \"Middle Finger\": 12,\n",
    "    \"Ring Finger\": 16,\n",
    "    \"Pinky Finger\": 20,\n",
    "}\n",
    "\n",
    "# --- Distance Calculation Function ---\n",
    "def calculate_distance(df, lm_a_idx, lm_b_idx):\n",
    "    \"\"\"Calculates the 3D normalized distance between two landmarks.\"\"\"\n",
    "    lm_a = df.loc[lm_a_idx]\n",
    "    lm_b = df.loc[lm_b_idx]\n",
    "    norm_dist = np.sqrt(\n",
    "        (lm_a[\"x_norm\"] - lm_b[\"x_norm\"])**2 +\n",
    "        (lm_a[\"y_norm\"] - lm_b[\"y_norm\"])**2 +\n",
    "        (lm_a[\"z_norm\"] - lm_b[\"z_norm\"])**2\n",
    "    )\n",
    "    return norm_dist\n",
    "\n",
    "# --- Tkinter Application Class ---\n",
    "class HandTrackingApp:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"✋ Hand Gesture Analyzer (Live Feed Fixed)\")\n",
    "        master.geometry(\"1000x700\")\n",
    "        master.configure(bg=\"#f4f7f6\")\n",
    "        \n",
    "        # Initialize self.photo here for robustness against GC\n",
    "        self.photo = None \n",
    "\n",
    "        # --- Frames for layout ---\n",
    "        self.main_frame = ttk.Frame(master, padding=\"15 15 15 15\")\n",
    "        self.main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.video_frame = ttk.LabelFrame(self.main_frame, text=\"Live Hand Tracking\", padding=\"10 10 10 10\")\n",
    "        self.video_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "\n",
    "        self.data_frame = ttk.Frame(self.main_frame, padding=\"10 10 10 10\", width=300)\n",
    "        self.data_frame.pack(side=tk.RIGHT, fill=tk.Y, padx=10, pady=10)\n",
    "        \n",
    "        # Handedness Header\n",
    "        self.handedness_label = ttk.Label(self.data_frame, text=\"Detecting Hand...\", font=('Arial', 16, 'bold'), foreground='navy')\n",
    "        self.handedness_label.pack(anchor='w', pady=(0, 15))\n",
    "\n",
    "        # --- Video Canvas (Display) ---\n",
    "        self.video_label = tk.Label(self.video_frame, bg=\"black\")\n",
    "        self.video_label.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # --- Data Labels ---\n",
    "        self.distance_labels = {}\n",
    "        for finger_name in FINGER_TIPS_INDICES.keys():\n",
    "            label_text = f\"↔️ {finger_name} Distance:\"\n",
    "            label = ttk.Label(self.data_frame, text=label_text, font=('Arial', 12, 'bold'))\n",
    "            label.pack(anchor='w', pady=(10, 2))\n",
    "            \n",
    "            value_label = ttk.Label(self.data_frame, text=\"--.-- (Normalized)\", font=('Courier', 14))\n",
    "            value_label.pack(anchor='w', pady=(0, 10))\n",
    "            self.distance_labels[finger_name] = value_label\n",
    "\n",
    "        # --- Status Label ---\n",
    "        self.status_label = ttk.Label(self.data_frame, text=\"Status: Initializing...\", font=('Arial', 10), foreground='gray')\n",
    "        self.status_label.pack(anchor='s', pady=(20, 0))\n",
    "\n",
    "        # --- Webcam Setup ---\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        if not self.cap.isOpened():\n",
    "            self.status_label.config(text=\"Status: CAMERA ERROR! Check connection or permissions.\", foreground='red')\n",
    "            # Use after to prevent immediate exit if camera fails\n",
    "            self.master.after(100, lambda: self.status_label.config(text=\"Status: CAMERA ERROR!\", foreground='red')) \n",
    "            return\n",
    "        \n",
    "        self.hands_processor = hands \n",
    "        self.update_video()\n",
    "\n",
    "    def update_video(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            img_h, img_w = frame.shape[:2]\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            results = self.hands_processor.process(frame_rgb)\n",
    "            \n",
    "            annotated_frame = frame.copy()\n",
    "            status_text = \"No Hand Detected\"\n",
    "            status_color = 'orange'\n",
    "            \n",
    "            self.handedness_label.config(text=\"No Hand Detected\", foreground='navy')\n",
    "\n",
    "            if results.multi_hand_landmarks and len(results.multi_hand_landmarks) > 0:\n",
    "                hand_landmarks = results.multi_hand_landmarks[0]\n",
    "                \n",
    "                handedness_proto = results.multi_handedness[0]\n",
    "                handedness_dict = MessageToDict(handedness_proto)\n",
    "                handedness = handedness_dict['classification'][0]['label'] \n",
    "                \n",
    "                self.handedness_label.config(text=f\"Hand Detected: {handedness}\", \n",
    "                                             foreground='darkgreen' if handedness == 'Right' else 'darkred')\n",
    "                \n",
    "                mp_drawing.draw_landmarks(\n",
    "                    annotated_frame, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(0, 255, 100), thickness=2, circle_radius=4), \n",
    "                    mp_drawing.DrawingSpec(color=(200, 200, 255), thickness=2, circle_radius=2)\n",
    "                )\n",
    "\n",
    "                rows = []\n",
    "                for idx, lm in enumerate(hand_landmarks.landmark):\n",
    "                    rows.append({\n",
    "                        \"index\": idx,\n",
    "                        \"x_norm\": lm.x, \"y_norm\": lm.y, \"z_norm\": lm.z,\n",
    "                        \"x_px\": int(lm.x * img_w), \"y_px\": int(lm.y * img_h)\n",
    "                    })\n",
    "                df = pd.DataFrame(rows).set_index(\"index\")\n",
    "\n",
    "                status_text = f\"Tracking {handedness} Hand\"\n",
    "                status_color = 'green'\n",
    "                \n",
    "                for finger_name, tip_idx in FINGER_TIPS_INDICES.items():\n",
    "                    if tip_idx in df.index and THUMB_TIP_IDX in df.index:\n",
    "                        norm_dist = calculate_distance(df, THUMB_TIP_IDX, tip_idx)\n",
    "                        self.distance_labels[finger_name].config(text=f\"{norm_dist:.4f} (Normalized)\", foreground='green')\n",
    "                        \n",
    "                        thumb_tip = df.loc[THUMB_TIP_IDX]\n",
    "                        finger_tip = df.loc[tip_idx]\n",
    "                        cv2.line(annotated_frame, \n",
    "                                 (thumb_tip[\"x_px\"], thumb_tip[\"y_px\"]),\n",
    "                                 (finger_tip[\"x_px\"], finger_tip[\"y_px\"]),\n",
    "                                 (0, 255, 0), 2)\n",
    "                    else:\n",
    "                        self.distance_labels[finger_name].config(text=\"--.-- (Missing Landmark)\", foreground='gray')\n",
    "            \n",
    "            else:\n",
    "                for label in self.distance_labels.values():\n",
    "                    label.config(text=\"--.-- (Normalized)\", foreground='gray')\n",
    "\n",
    "\n",
    "            self.status_label.config(text=f\"Status: {status_text}\", foreground=status_color)\n",
    "\n",
    "            # Convert to PIL Image for Tkinter\n",
    "            img = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(img)\n",
    "            \n",
    "            width, height = self.video_label.winfo_width(), self.video_label.winfo_height()\n",
    "            if width > 10 and height > 10: \n",
    "                img = img.resize((width, height), Image.Resampling.LANCZOS)\n",
    "            \n",
    "            # THE FINAL FIX: Storing the reference on self.photo ensures persistence.\n",
    "            self.photo = ImageTk.PhotoImage(image=img)\n",
    "            self.video_label.config(image=self.photo)\n",
    "            \n",
    "        # Loop the update function\n",
    "        self.master.after(10, self.update_video) \n",
    "\n",
    "    def on_closing(self):\n",
    "        print(\"Closing application and releasing webcam...\")\n",
    "        self.cap.release()\n",
    "        self.hands_processor.close()\n",
    "        self.master.destroy()\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        root = tk.Tk()\n",
    "        style = ttk.Style(root)\n",
    "        style.theme_use('clam') \n",
    "        \n",
    "        app = HandTrackingApp(root)\n",
    "        root.protocol(\"WM_DELETE_WINDOW\", app.on_closing)\n",
    "        root.mainloop()\n",
    "    except Exception as e:\n",
    "        print(f\"An external error occurred: {e}\")\n",
    "        hands.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cv_project)",
   "language": "python",
   "name": "cv_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
